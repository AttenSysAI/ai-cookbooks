{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6520bc60",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<p align=\"center\" style=\"width: 100%;\">\n",
    "    <img src=\"https://raw.githubusercontent.com/vlm-run/.github/refs/heads/main/profile/assets/vlm-black.svg\" alt=\"VLM Run Logo\" width=\"80\" style=\"margin-bottom: -5px; color: #2e3138; vertical-align: middle; padding-right: 5px;\"><br>\n",
    "</p>\n",
    "<p align=\"center\"><a href=\"https://docs.vlm.run\"><b>Website</b></a> | <a href=\"https://docs.vlm.run/\"><b>API Docs</b></a> | <a href=\"https://docs.vlm.run/blog\"><b>Blog</b></a> | <a href=\"https://discord.gg/AMApC2UzVY\"><b>Discord</b></a> | <a href=\"https://chat.vlm.run\"><b>Chat</b></a>\n",
    "</p>\n",
    "</div>\n",
    "\n",
    "# VLM Run Orion - Interior Design Ergonomics Audit\n",
    "\n",
    "This notebook demonstrates how to use [VLM Run Orion's](https://vlm.run/orion) vision capabilities to act as a Certified Professional Ergonomist. You can upload a photo of a home office setup and ask the model to critique the ergonomics and suggest improvements.\n",
    "\n",
    "For more details on the API, see the [Agent API docs](https://docs.vlm.run/agents/introduction).\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Python 3.10+\n",
    "- VLM Run API key (get one at [app.vlm.run](https://app.vlm.run))\n",
    "- VLM Run Python Client with OpenAI extra `vlmrun[openai]`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14eb9524",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, install the required packages and configure the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbc13e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "%pip install vlmrun[openai] --upgrade --quiet\n",
    "%pip install cachetools pillow requests numpy --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85e4014e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "VLMRUN_API_KEY = os.getenv(\"VLMRUN_API_KEY\", None)\n",
    "if VLMRUN_API_KEY is None:\n",
    "    VLMRUN_API_KEY = getpass.getpass(\"Enter your VLM Run API key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cef00a",
   "metadata": {},
   "source": [
    "## Initialize the VLM Run Client\n",
    "\n",
    "We use the OpenAI-compatible chat completions interface through the VLM Run SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea6a90cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLM Run client initialized successfully!\n",
      "Base URL: https://agent.vlm.run/v1\n"
     ]
    }
   ],
   "source": [
    "from vlmrun.client import VLMRun\n",
    "\n",
    "BASE_URL = os.getenv(\"VLMRUN_BASE_URL\", \"https://agent.vlm.run/v1\")\n",
    "client = VLMRun(api_key=VLMRUN_API_KEY, base_url=BASE_URL)\n",
    "print(\"VLM Run client initialized successfully!\")\n",
    "print(f\"Base URL: {BASE_URL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ba842a",
   "metadata": {},
   "source": [
    "## Response Models\n",
    "\n",
    "We define Pydantic models for structured outputs. The report will be returned as a structured object containing specific sections like Visual Ergonomic Assessment, Risk Identification, and Actionable Recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af68e882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response models defined successfully!\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class ErgonomicAssessment(BaseModel):\n",
    "    \"\"\"Detailed evaluation of key ergonomic elements.\"\"\"\n",
    "    monitor_placement: str = Field(..., description=\"Assessment of height, tilt, and distance relative to the user\")\n",
    "    seating_mechanics: str = Field(..., description=\"Critique of lumbar support, seat pan depth, and backrest angle\")\n",
    "    input_device_alignment: str = Field(..., description=\"Height and position of keyboard/mouse relative to armrests\")\n",
    "    lighting_and_glare: str = Field(..., description=\"Identification of lighting sources and potential glare zones\")\n",
    "\n",
    "\n",
    "class Recommendations(BaseModel):\n",
    "    \"\"\"Actionable adjustments to optimize the setup.\"\"\"\n",
    "    immediate_fixes: List[str] = Field(..., description=\"Adjustments that can be made instantly\")\n",
    "    behavioral_adjustments: List[str] = Field(..., description=\"Changes in user posture or habits\")\n",
    "    equipment_suggestions: List[str] = Field(..., description=\"New gear or furniture to consider\")\n",
    "\n",
    "\n",
    "class ErgonomicsAudit(BaseModel):\n",
    "    \"\"\"Structured report for an ergonomic workspace audit.\"\"\"\n",
    "    visual_assessment: ErgonomicAssessment = Field(..., description=\"Visual evaluation of the workspace components\")\n",
    "    risk_identification: List[str] = Field(..., description=\"Specific areas that may lead to symptoms like MSDs, eye strain, etc.\")\n",
    "    recommendations: Recommendations = Field(..., description=\"Categorized list of improvements\")\n",
    "\n",
    "\n",
    "print(\"Response models defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cbff3e",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n",
    "We create helper functions to simplify making chat completion requests with structured outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14299c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions defined!\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "import json\n",
    "from typing import Any, Type, TypeVar\n",
    "\n",
    "import cachetools\n",
    "from vlmrun.common.image import encode_image\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "T = TypeVar('T', bound=BaseModel)\n",
    "\n",
    "\n",
    "def custom_key(prompt: str, image_path: str | None = None, response_model: Type[T] | None = None, model: str = \"vlmrun-orion-1:auto\"):\n",
    "    \"\"\"Custom key for caching chat_completion.\"\"\"\n",
    "    response_key = hashlib.sha256(json.dumps(response_model.model_json_schema(), sort_keys=True).encode()).hexdigest() if response_model else \"\"\n",
    "    image_key = hashlib.sha256(image_path.encode()).hexdigest() if image_path else \"\"\n",
    "    return (prompt, image_key, response_key, model)\n",
    "\n",
    "\n",
    "@cachetools.cached(cache=cachetools.TTLCache(maxsize=100, ttl=3600), key=custom_key)\n",
    "def chat_completion(\n",
    "    prompt: str,\n",
    "    image_path: str | None = None,\n",
    "    response_model: Type[T] | None = None,\n",
    "    model: str = \"vlmrun-orion-1:auto\"\n",
    ") -> tuple[BaseModel | str, str]:\n",
    "    \"\"\"\n",
    "    Make a chat completion request with structured output for Ergonomics Audit.\n",
    "\n",
    "    Args:\n",
    "        prompt: The prompt describing the audit task\n",
    "        image_path: Path to the image file (Home office setup)\n",
    "        response_model: Pydantic model for structured output\n",
    "        model: Model to use (default: vlmrun-orion-1:auto)\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (parsed response model or text, session_id)\n",
    "    \"\"\"\n",
    "    content = [{\"type\": \"text\", \"text\": prompt}]\n",
    "    \n",
    "    # Add image if provided\n",
    "    if image_path:\n",
    "        image = Image.open(image_path)\n",
    "        image_data = encode_image(image, format=\"JPEG\")\n",
    "        content.append({\"type\": \"image_url\", \"image_url\": {\"url\": image_data}})\n",
    "\n",
    "    kwargs = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": content}]\n",
    "    }\n",
    "\n",
    "    if response_model:\n",
    "        kwargs[\"response_format\"] = {\n",
    "            \"type\": \"json_schema\",\n",
    "            \"schema\": response_model.model_json_schema()\n",
    "        }\n",
    "\n",
    "    response = client.agent.completions.create(**kwargs)\n",
    "    response_text = response.choices[0].message.content\n",
    "    session_id = response.session_id\n",
    "\n",
    "    if response_model:\n",
    "        result = response_model.model_validate_json(response_text)\n",
    "        return result, session_id\n",
    "\n",
    "    return response_text, session_id\n",
    "\n",
    "print(\"Helper functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69692d3c",
   "metadata": {},
   "source": [
    "## Ergonomics Audit\n",
    "\n",
    "Upload a photo of a home office setup and ask the VLM to critique the ergonomics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6003d19b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ergonomics prompt prepared!\n",
      "\\nPrompt length: 1441 characters\n"
     ]
    }
   ],
   "source": [
    "# Prompt for Ergonomics Assessment\n",
    "ERGONOMICS_PROMPT = \"\"\"\n",
    "Task: Act as a Certified Professional Ergonomist (CPE). Analyze the attached photo of a home office setup and provide a detailed critique of the workspace layout relative to human factors and physical health.\n",
    "\n",
    "Instructions:\n",
    "\n",
    "Visual Ergonomic Assessment: Evaluate the following key elements visible in the image:\n",
    "\n",
    "Monitor Placement: Assess height relative to eye level, tilt, and estimated distance from the user's seated position. Check for potential neck strain or \"tech neck\" indicators.\n",
    "\n",
    "Seating Mechanics: Critique the chair's lumbar support, seat pan depth, and the angle of the backrest.\n",
    "\n",
    "Input Device Alignment: Observe the height and position of the keyboard and mouse relative to the armrests and desk surface. Look for potential wrist extension or shoulder shrugging.\n",
    "\n",
    "Lighting and Glare: Identify potential sources of eye strain, such as unshielded windows or poorly placed lamps reflecting off screens.\n",
    "\n",
    "Risk Identification: Highlight specific areas that may lead to Musculoskeletal Disorders (MSDs), such as carpal tunnel syndrome, lower back pain, or cervical tension.\n",
    "\n",
    "Actionable Recommendations: Provide a numbered list of adjustments to optimize the setup. Categorize these into:\n",
    "\n",
    "Immediate Fixes: (e.g., \"Raise monitor by 3 inches using a riser.\")\n",
    "\n",
    "Behavioral Adjustments: (e.g., \"Ensure feet are flat on the floor.\")\n",
    "\n",
    "Equipment Suggestions: (e.g., \"Consider an external keyboard to allow for better screen positioning.\")\n",
    "\"\"\"\n",
    "\n",
    "print(\"Ergonomics prompt prepared!\")\n",
    "print(f\"\\\\nPrompt length: {len(ERGONOMICS_PROMPT)} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751aa6de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> RESPONSE\n",
      "visual_assessment=ErgonomicAssessment(monitor_placement='The main monitor is well-positioned on a riser, likely keeping the top of the screen at eye level. However, the laptop screen is significantly lower, necessitating harmful downward neck flexion.', seating_mechanics='The chair provides excellent lumbar support and a contoured mesh backrest. The seat pan depth and slightly reclined backrest angle are conducive to healthy circulation and spinal alignment.', input_device_alignment='Keyboard and mouse are placed directly on the desk surface. There is a high likelihood of wrist extension because the chair armrests appear low, potentially leaving the forearms unsupported during use.', lighting_and_glare='The large window to the right is a primary source of glare. While the blinds offer some control, unshielded light reflecting off the screen can lead to significant eye fatigue.') risk_identification=[\"Neck Strain ('Tech Neck'): High risk if the laptop screen is used frequently in its current low position.\", 'Wrist Strain/Carpal Tunnel: Moderate to high risk due to potential wrist extension and lack of forearm support on the desk surface.', 'Eye Strain: Potential due to significant glare from the adjacent window and the low-positioned laptop screen.', 'Shoulder Tension: Possible muscle strain from shrugging to reach the desk if the chair height and armrests are not optimally aligned.'] recommendations=Recommendations(immediate_fixes=['Adjust chair armrests to a height where forearms are parallel to the floor, providing support to the elbows and reducing strain on wrists and shoulders.', 'Adjust the window blinds to eliminate direct glare on the monitor screens throughout the day.', 'If the laptop is a primary display, place it on a temporary riser (like a stack of books) until a stand is acquired.'], behavioral_adjustments=[\"Implement the '20-20-20 rule': every 20 minutes, look at something 20 feet away for 20 seconds to reduce eye strain.\", 'Take short movement and stretching breaks every 30-60 minutes to combat static posture.', 'Be mindful of neutral wrist posture, ensuring wrists remain straight and not bent upwards while typing or mousing.'], equipment_suggestions=['A dedicated laptop stand is essential to raise the laptop screen to eye level if it is used for extended periods.', 'An external keyboard and mouse are necessary if the laptop is raised on a stand to maintain ergonomic input alignment.', 'Consider a desk lamp for focused task lighting to reduce overall screen contrast and eye strain.'])\n",
      "\\n>> SESSION ID: ae8bcc06-51c6-46ce-a582-2bcb85356fce\n",
      "\\n>> ERGONOMICS AUDIT REPORT\n",
      "================================================================================\n",
      "Visual Assessment:\n",
      "- Monitor: The main monitor is well-positioned on a riser, likely keeping the top of the screen at eye level. However, the laptop screen is significantly lower, necessitating harmful downward neck flexion.\n",
      "- Seating: The chair provides excellent lumbar support and a contoured mesh backrest. The seat pan depth and slightly reclined backrest angle are conducive to healthy circulation and spinal alignment.\n",
      "- Inputs: Keyboard and mouse are placed directly on the desk surface. There is a high likelihood of wrist extension because the chair armrests appear low, potentially leaving the forearms unsupported during use.\n",
      "- Lighting: The large window to the right is a primary source of glare. While the blinds offer some control, unshielded light reflecting off the screen can lead to significant eye fatigue.\\n\n",
      "Risk Identification:\n",
      "!! Neck Strain ('Tech Neck'): High risk if the laptop screen is used frequently in its current low position.\n",
      "!! Wrist Strain/Carpal Tunnel: Moderate to high risk due to potential wrist extension and lack of forearm support on the desk surface.\n",
      "!! Eye Strain: Potential due to significant glare from the adjacent window and the low-positioned laptop screen.\n",
      "!! Shoulder Tension: Possible muscle strain from shrugging to reach the desk if the chair height and armrests are not optimally aligned.\n",
      "\\nRecommendations:\n",
      "Immediate Fixes:\n",
      "- Adjust chair armrests to a height where forearms are parallel to the floor, providing support to the elbows and reducing strain on wrists and shoulders.\n",
      "- Adjust the window blinds to eliminate direct glare on the monitor screens throughout the day.\n",
      "- If the laptop is a primary display, place it on a temporary riser (like a stack of books) until a stand is acquired.\n",
      "\\nBehavioral:\n",
      "- Implement the '20-20-20 rule': every 20 minutes, look at something 20 feet away for 20 seconds to reduce eye strain.\n",
      "- Take short movement and stretching breaks every 30-60 minutes to combat static posture.\n",
      "- Be mindful of neutral wrist posture, ensuring wrists remain straight and not bent upwards while typing or mousing.\n",
      "\\nEquipment:\n",
      "- A dedicated laptop stand is essential to raise the laptop screen to eye level if it is used for extended periods.\n",
      "- An external keyboard and mouse are necessary if the laptop is raised on a stand to maintain ergonomic input alignment.\n",
      "- Consider a desk lamp for focused task lighting to reduce overall screen contrast and eye strain.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Note: Ensure you have a 'home_office.jpg' in the 'files' directory or update the path below.\n",
    "image_path = \"home_office.jpeg\" \n",
    "\n",
    "# Verify if image exists to avoid errors in this example execution\n",
    "if os.path.exists(image_path):\n",
    "    result, session_id = chat_completion(\n",
    "        prompt=ERGONOMICS_PROMPT,\n",
    "        image_path=image_path,\n",
    "        response_model=ErgonomicsAudit,\n",
    "        model=\"vlmrun-orion-1:auto\"\n",
    "    )\n",
    "\n",
    "    print(\">> RESPONSE\")\n",
    "    print(result)\n",
    "    print(f\"\\\\n>> SESSION ID: {session_id}\")\n",
    "    \n",
    "    print(\"\\\\n>> ERGONOMICS AUDIT REPORT\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"Visual Assessment:\")\n",
    "    print(f\"- Monitor: {result.visual_assessment.monitor_placement}\")\n",
    "    print(f\"- Seating: {result.visual_assessment.seating_mechanics}\")\n",
    "    print(f\"- Inputs: {result.visual_assessment.input_device_alignment}\")\n",
    "    print(f\"- Lighting: {result.visual_assessment.lighting_and_glare}\\\\n\")\n",
    "    print(\"Risk Identification:\")\n",
    "    for risk in result.risk_identification:\n",
    "        print(f\"!! {risk}\")\n",
    "    print(\"\\\\nRecommendations:\")\n",
    "    print(\"Immediate Fixes:\")\n",
    "    for fix in result.recommendations.immediate_fixes:\n",
    "        print(f\"- {fix}\")\n",
    "    print(\"\\\\nBehavioral:\")\n",
    "    for beh in result.recommendations.behavioral_adjustments:\n",
    "        print(f\"- {beh}\")\n",
    "    print(\"\\\\nEquipment:\")\n",
    "    for eq in result.recommendations.equipment_suggestions:\n",
    "        print(f\"- {eq}\")\n",
    "    print(\"=\" * 80)\n",
    "else:\n",
    "    print(f\"Image not found at {image_path}. Please add a home office image to run this example.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1eb60b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated how to use **VLM Run Orion** to perform an ergonomics audit of a workspace.\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Human Factors Analysis**: The model can evaluate the physical relationship between a user and their environment using only visual cues.\n",
    "2. **Preventative Healthcare**: By identifying risk factors for MSDs, this tool can serve as a first-line assessment for occupational health.\n",
    "3. **Structured Advice**: Grouping recommendations into \"Immediate,\" \"Behavioral,\" and \"Equipment\" makes the advice practical and easy to implement.\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Use the model to assess standing desk setups.\n",
    "- Integrate with a chatbot to interactive ergonomic coaching.\n",
    "- Explore the [VLM Run Documentation](https://docs.vlm.run) for more capabilities.\n",
    "\n",
    "Stay healthy and comfortable! ðŸª‘"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
