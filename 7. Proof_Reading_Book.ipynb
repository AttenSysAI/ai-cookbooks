{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0b7f2dc7",
      "metadata": {
        "id": "0b7f2dc7"
      },
      "source": [
        "<div align=\"center\">\n",
        "<p align=\"center\" style=\"width: 100%;\">\n",
        "    <img src=\"https://raw.githubusercontent.com/vlm-run/.github/refs/heads/main/profile/assets/vlm-black.svg\" alt=\"VLM Run Logo\" width=\"80\" style=\"margin-bottom: -5px; color: #2e3138; vertical-align: middle; padding-right: 5px;\"><br>\n",
        "</p>\n",
        "<p align=\"center\">\n",
        "  <a href=\"https://docs.vlm.run\"><b>Website</b></a> | \n",
        "  <a href=\"https://docs.vlm.run/\"><b>API Docs</b></a> | \n",
        "  <a href=\"https://docs.vlm.run/blog\"><b>Blog</b></a> | \n",
        "  <a href=\"https://discord.gg/AMApC2UzVY\"><b>Discord</b></a> | \n",
        "  <a href=\"https://chat.vlm.run\"><b>Chat</b></a>\n",
        "</p>\n",
        "</div>\n",
        "\n",
        "# VLM Run Orion - Book Proofreading from PDF\n",
        "\n",
        "\n",
        "This comprehensive cookbook demonstrates [VLM Run Orion's](https://vlm.run/orion) capabilities to perform intelligent book proofreading directly from a PDF manuscript. Leveraging multimodal understanding and structured output, Orion can detect grammatical errors, stylistic inconsistencies, formatting issues, and even factual discrepancies‚Äîall with precise page references.\n",
        "\n",
        "For this notebook, we'll cover how to use the **VLM Run Agent Chat Completions API**‚Äîan OpenAI-compatible interface that supports image and data inputs alongside text‚Äîto generate plots directly from structured data.\n",
        "\n",
        "We'll cover the following topics:\n",
        "1. **Document Ingestion** ‚Äì Upload a book manuscript (PDF) via URL\n",
        "2. **Error Detection & Categorization** ‚Äì Identify grammar, style, and formatting issues\n",
        "3. **Structured Feedback** ‚Äì Get machine-readable results with page numbers and context\n",
        "4. **Multi-Pass Review** ‚Äì Chain operations (e.g., ‚Äúfirst check grammar, then verify character names‚Äù)\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "- Python 3.10+\n",
        "- VLM Run API key (get one at [app.vlm.run](https://app.vlm.run))\n",
        "- VLM Run Python Client with OpenAI extra: `pip install \"vlmrun[openai]\"`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43b58c5f",
      "metadata": {
        "id": "43b58c5f"
      },
      "source": [
        "## Setup\n",
        "\n",
        "First, install the required packages and configure the environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "53434b64",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53434b64",
        "outputId": "691e0956-41b4-4a5c-95fe-dc7b4ee00318"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
            "\n",
            "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install vlmrun[openai] --upgrade --quiet\n",
        "!pip install pillow requests numpy --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "fa9f8d78",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fa9f8d78",
        "outputId": "3b940c36-094d-4cbb-9a16-23f44049eadb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "import json\n",
        "from typing import List, Any\n",
        "from functools import cached_property\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "VLMRUN_API_KEY = os.getenv(\"VLMRUN_API_KEY\", None)\n",
        "if VLMRUN_API_KEY is None:\n",
        "    VLMRUN_API_KEY = getpass.getpass(\"Enter your VLM Run API key: \")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60b786ad",
      "metadata": {
        "id": "60b786ad"
      },
      "source": [
        "## Initialize the VLM Run Client\n",
        "\n",
        "We use the OpenAI-compatible chat completions interface through the VLM Run SDK."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "cf798bbb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf798bbb",
        "outputId": "1c7878de-e2fc-4832-eb62-c42b3e5ab524"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VLM Run client initialized successfully!\n",
            "Base URL: https://agent.vlm.run/v1\n",
            "Model: vlmrun-orion-1\n"
          ]
        }
      ],
      "source": [
        "from vlmrun.client import VLMRun\n",
        "\n",
        "client = VLMRun(\n",
        "    api_key=VLMRUN_API_KEY, base_url=\"https://agent.vlm.run/v1\", timeout=1000\n",
        ")\n",
        "print(\"VLM Run client initialized successfully!\")\n",
        "print(f\"Base URL: https://agent.vlm.run/v1\")\n",
        "print(f\"Model: vlmrun-orion-1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5df2b29e",
      "metadata": {
        "id": "5df2b29e"
      },
      "source": [
        "## Response Models (dtypes)\n",
        "\n",
        "We define structured Pydantic models to capture proofreading feedback with full traceability.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "010d3df2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "010d3df2",
        "outputId": "e9d166f7-370c-4cc0-cf6e-584481c93bf5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Proofreading response models defined!\n"
          ]
        }
      ],
      "source": [
        "class ProofreadingIssue(BaseModel):\n",
        "    issue_type: str = Field(..., description=\"Category: 'grammar', 'spelling', 'style', 'consistency', 'formatting', 'factual'\")\n",
        "    page_number: int = Field(..., description=\"Page where the issue occurs\")\n",
        "    excerpt: str = Field(..., description=\"Short quoted text containing the issue\")\n",
        "    context: str = Field(..., description=\"Surrounding paragraph for clarity\")\n",
        "    suggestion: str = Field(..., description=\"Recommended correction or improvement\")\n",
        "    severity: str = Field(..., description=\"One of: 'low', 'medium', 'high'\")\n",
        "\n",
        "class ProofreadingReport(BaseModel):\n",
        "    total_issues: int = Field(..., description=\"Total number of detected issues\")\n",
        "    issues_by_page: dict[int, int] = Field(..., description=\"Mapping of page ‚Üí issue count\")\n",
        "    issues: List[ProofreadingIssue] = Field(..., description=\"Full list of annotated issues\")\n",
        "    summary: str = Field(..., description=\"High-level overview of manuscript quality\")\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"ProofreadingReport(pages={len(self.issues_by_page)}, issues={self.total_issues}, severity_distribution={self._severity_dist()})\"\n",
        "\n",
        "    def _severity_dist(self):\n",
        "        from collections import Counter\n",
        "        counts = Counter(issue.severity for issue in self.issues)\n",
        "        return dict(counts)\n",
        "\n",
        "\n",
        "print(\"‚úÖ Proofreading response models defined!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b565e800",
      "metadata": {
        "id": "b565e800"
      },
      "source": [
        "## Helper Functions\n",
        "\n",
        "We create helper functions to simplify making chat completion requests with structured outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "f477c81b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f477c81b",
        "outputId": "5ec041bf-da87-4be4-fc0e-6e702f112a27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Helper functions defined!\n"
          ]
        }
      ],
      "source": [
        "import hashlib\n",
        "import cachetools\n",
        "from typing import Type, TypeVar\n",
        "from IPython.display import HTML\n",
        "from vlmrun.common.image import encode_image\n",
        "\n",
        "\n",
        "T = TypeVar('T', bound=BaseModel)\n",
        "\n",
        "\n",
        "def display(images: Image.Image | list[Image.Image], texts: list[str] | None = None, width: int = 300):\n",
        "    if isinstance(images, Image.Image):\n",
        "        images = [images]\n",
        "    if texts == None:\n",
        "        texts = [None] * len(images)\n",
        "    elif isinstance(texts, str):\n",
        "        texts = [texts]\n",
        "    elif len(texts) != len(images):\n",
        "        raise ValueError(\"`texts` must be a list of the same length as `images`\")\n",
        "\n",
        "    imgs_html = \"\"\n",
        "    for image, text in zip(images, texts):\n",
        "        W, H = image.size\n",
        "        if W > width:\n",
        "            H = int(H * width / W)\n",
        "            W = width\n",
        "            image = image.resize((W, H))\n",
        "        im_bytes = encode_image(image, format=\"JPEG\")\n",
        "        imgs_html += f\"<div style='display:inline-block; margin:5px; text-align:center'>\"\n",
        "        imgs_html += f\"<img src='{im_bytes}' style='width:{width}px; border-radius:6px'>\"\n",
        "        if text:\n",
        "            imgs_html += f\"<div style='font-size:12px; color:#666; margin-top:5px'>{text}</div>\"\n",
        "        imgs_html += f\"</div>\"\n",
        "    return HTML(f\"<div style='display:flex; flex-wrap:wrap'>{imgs_html}</div>\")\n",
        "\n",
        "\n",
        "def custom_key(prompt: str, images: list[Image.Image] | list[str] | None = None, doc: list[str] | None = None, response_model: Type[T] | None = None, model: str = \"vlmrun-orion-1:auto\"):\n",
        "    \"\"\"Custom key for caching chat_completion.\"\"\"\n",
        "    image_keys = []\n",
        "    if images:\n",
        "        for image in images:\n",
        "            if isinstance(image, Image.Image):\n",
        "                thumb = image.copy()\n",
        "                thumb.thumbnail((128, 128))\n",
        "                encoded = encode_image(thumb, format=\"JPEG\")\n",
        "                image_keys.append(encoded)\n",
        "            elif isinstance(image, str):\n",
        "                image_keys.append(image)\n",
        "\n",
        "    doc_keys = []\n",
        "    if doc:\n",
        "        if isinstance(doc, str):\n",
        "            doc_keys.append(doc)\n",
        "        elif isinstance(doc, list):\n",
        "            for d_url in doc:\n",
        "                doc_keys.append(d_url)\n",
        "\n",
        "    response_key = hashlib.sha256(json.dumps(response_model.model_json_schema(), sort_keys=True).encode()).hexdigest() if response_model else \"\"\n",
        "    return (prompt, tuple(image_keys), tuple(doc_keys), response_key, model)\n",
        "\n",
        "\n",
        "@cachetools.cached(cache=cachetools.TTLCache(maxsize=1000, ttl=3600), key=custom_key)\n",
        "def chat_completion(\n",
        "    prompt: str,\n",
        "    images: list[Image.Image] | list[str] | None = None,\n",
        "    doc: list[str] | None = None,\n",
        "    response_model: Type[T] | None = None,\n",
        "    model: str = \"vlmrun-orion-1:auto\"\n",
        ") -> Any:\n",
        "    \"\"\"\n",
        "    Make a chat completion request with optional images and structured output.\n",
        "\n",
        "    Args:\n",
        "        prompt: The text prompt/instruction\n",
        "        images: Optional list of images to process (either PIL Images or URLs)\n",
        "        response_model: Optional Pydantic model for structured output\n",
        "        model: Model to use (default: vlmrun-orion-1:auto)\n",
        "\n",
        "    Returns:\n",
        "        Parsed response model if response_model provided, else raw response text\n",
        "    \"\"\"\n",
        "    content = []\n",
        "    content.append({\"type\": \"text\", \"text\": prompt})\n",
        "    if doc:\n",
        "        if isinstance(doc, str):\n",
        "            content.append({\n",
        "                    \"type\": \"file_url\",\n",
        "                    \"file_url\": {\"url\": doc, \"detail\": \"auto\"}\n",
        "                })\n",
        "        elif isinstance(doc, list):\n",
        "            for d_url in doc:\n",
        "                assert isinstance(d_url, str) and d_url.startswith(\"http\"), \"Document URLs must be strings starting with http or https\"\n",
        "                content.append({\n",
        "                    \"type\": \"file_url\",\n",
        "                    \"file_url\": {\"url\": d_url, \"detail\": \"auto\"}\n",
        "                })\n",
        "\n",
        "\n",
        "    if images:\n",
        "        for image in images:\n",
        "            if isinstance(image, str):\n",
        "                assert image.startswith(\"http\"), \"Image URLs must start with http or https\"\n",
        "                content.append({\n",
        "                    \"type\": \"image_url\",\n",
        "                    \"image_url\": {\"url\": image, \"detail\": \"auto\"}\n",
        "                })\n",
        "            elif isinstance(image, Image.Image):\n",
        "                content.append({\n",
        "                    \"type\": \"image_url\",\n",
        "                    \"image_url\": {\"url\": encode_image(image, format=\"JPEG\"), \"detail\": \"auto\"}\n",
        "                })\n",
        "            else:\n",
        "                raise ValueError(\"Images must be either PIL Images or URLs\")\n",
        "\n",
        "    kwargs = {\n",
        "        \"model\": model,\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": content}]\n",
        "    }\n",
        "\n",
        "    if response_model:\n",
        "        kwargs[\"response_format\"] = {\n",
        "            \"type\": \"json_schema\",\n",
        "            \"schema\": response_model.model_json_schema()\n",
        "        }\n",
        "\n",
        "    response = client.agent.completions.create(**kwargs)\n",
        "    response_text = response.choices[0].message.content\n",
        "\n",
        "    if response_model:\n",
        "        return response_model.model_validate_json(response_text), response.session_id\n",
        "\n",
        "    return response_text, response.session_id\n",
        "\n",
        "print(\"Helper functions defined!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd5579ed",
      "metadata": {
        "id": "cd5579ed"
      },
      "source": [
        "### 1. Basic Proofreading Pass\n",
        "\n",
        "\n",
        "Upload a book manuscript and request a full proofreading review."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "435a8e69",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 644
        },
        "id": "435a8e69",
        "outputId": "4dede5ef-b628-463d-a04c-1d09550a351d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÑ Manuscript analyzed across 0 pages\n",
            "‚ùó Total issues found: 6\n",
            "üìä Severity: {'high': 2, 'medium': 2, 'low': 2}\n",
            "\n",
            "üìù Summary:\n",
            "The manuscript proofreading pass revealed critical consistency issues, primarily a mismatch between the worksheet content (Worksheet 6) and the provided answer key (Worksheet 1). There is also a factual error in the instructions, which refer to 'circled' words that are not actually circled. Minor grammar and formatting adjustments are recommended to improve pedagogical clarity and professional presentation.\n"
          ]
        }
      ],
      "source": [
        "# BOOK_URL = \"https://web.stanford.edu/~zwicky/mistakes.pdf\" \n",
        "BOOK_URL= \"https://www.oasisacademywoodview.org/uploaded/Woodview/home_learning/year4/week4/Tuesday_English.pdf\"\n",
        "report, session_id = chat_completion(\n",
        "    prompt=(\n",
        "        \"Perform a professional proofreading pass on this book manuscript. \"\n",
        "        \"Identify grammar, spelling, punctuation, and basic style issues. \"\n",
        "        \"Return every issue with its page number, excerpt, context, and a suggested fix. \"\n",
        "        \"Prioritize clarity and readability.\"\n",
        "    ),\n",
        "    doc=BOOK_URL,\n",
        "    response_model=ProofreadingReport\n",
        ")\n",
        "\n",
        "print(f\"üìÑ Manuscript analyzed across {len(report.issues_by_page)} pages\")\n",
        "print(f\"‚ùó Total issues found: {report.total_issues}\")\n",
        "print(f\"üìä Severity: {report._severity_dist()}\")\n",
        "print(f\"\\nüìù Summary:\\n{report.summary}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "acf8dbd8",
      "metadata": {
        "id": "acf8dbd8"
      },
      "source": [
        "### 2. Style & Consistency Check\n",
        "\n",
        "\n",
        "\n",
        "Now focus on authorial voice and narrative consistency."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "0c6cdaad",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        },
        "id": "0c6cdaad",
        "outputId": "0e603700-dcf8-4c48-c0ab-ee0166f92109"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç Consistency issues: 4\n",
            "\n",
            "Page 6 | Timeline (high)\n",
            "Excerpt: ‚Äú\"Mistake (6)\" (Page 6) vs. \"Mistake (1) Answers\" (Page 7)‚Äù\n",
            "Suggestion: Reorder the manuscript so that the answer key immediately following \"Mistake (6)\" corresponds to the questions asked on that page. Ensure the numbering of the sets follows a logical numerical order.\n",
            "\n",
            "Page 6 | Spelling (medium)\n",
            "Excerpt: ‚Äú\"Mickey was poppuler at school.\" vs. \"What hite is Dad compared to Mike?\"‚Äù\n",
            "Suggestion: Determine if \"Mickey\" and \"Mike\" are intended to be the same character; if so, standardize the spelling to one version throughout the manuscript.\n",
            "\n",
            "Page 6 | Style (medium)\n",
            "Excerpt: ‚Äú\"The spelling mistakes in these sentences have been circled...\" / \"Each sentence below has one word that is incorrect...\"‚Äù\n",
            "Suggestion: Use a single set of instructions at the top of the page or simplify subsequent instructions to reduce clutter.\n"
          ]
        }
      ],
      "source": [
        "consistency_report, _ = chat_completion(\n",
        "    prompt=(\n",
        "        \"Review the manuscript for stylistic consistency: \"\n",
        "        \"- Character name spellings (e.g., 'Jon' vs 'John') \"\n",
        "        \"- Timeline contradictions \"\n",
        "        \"- POV shifts or tense inconsistencies \"\n",
        "        \"- Repetitive phrasing or overused words \"\n",
        "        \"Only report high- or medium-severity issues with page numbers.\"\n",
        "    ),\n",
        "    doc=BOOK_URL,\n",
        "    response_model=ProofreadingReport\n",
        ")\n",
        "\n",
        "print(f\"üîç Consistency issues: {consistency_report.total_issues}\")\n",
        "for issue in consistency_report.issues[:3]:  # Show top 3\n",
        "    print(f\"\\nPage {issue.page_number} | {issue.issue_type.title()} ({issue.severity})\")\n",
        "    print(f\"Excerpt: ‚Äú{issue.excerpt}‚Äù\")\n",
        "    print(f\"Suggestion: {issue.suggestion}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd2f704c",
      "metadata": {
        "id": "fd2f704c"
      },
      "source": [
        "### 3. Formatting & Publishing Readiness\n",
        "\n",
        "Check for typesetting and publishing standards."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "25a98b2a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "25a98b2a",
        "outputId": "f577fb84-2d25-4d56-f2b8-c255990a7e30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìê Formatting issues: 4\n"
          ]
        }
      ],
      "source": [
        "format_report, _ = chat_completion(\n",
        "    prompt=(\n",
        "        \"Evaluate the manuscript for publishing-ready formatting: \"\n",
        "        \"- Missing chapter headings \"\n",
        "        \"- Improper dialogue punctuation (e.g., missing em-dashes or quotes) \"\n",
        "        \"- Inconsistent heading levels or spacing \"\n",
        "        \"- Page breaks in awkward places (e.g., mid-paragraph) \"\n",
        "        \"Assume this is for print-on-demand paperback.\"\n",
        "    ),\n",
        "    doc=BOOK_URL,\n",
        "    response_model=ProofreadingReport\n",
        ")\n",
        "\n",
        "print(f\"üìê Formatting issues: {format_report.total_issues}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "baa3fdbe",
      "metadata": {},
      "source": [
        "### 4. Generate an Editor‚Äôs Summary Dashboard\n",
        "\n",
        "Combine all passes into a single editorial dashboard."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "6e90b185",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìã EDITORIAL DASHBOARD\n",
            "Pages: 2\n",
            "Grammar: 0 | Consistency: 3 | Formatting: 0\n",
            "üö® Critical pages: []\n",
            "\n",
            "The manuscript displays a critical mismatch where Worksheet (6) is followed by an Answer Key for Worksheet (1). This error is compounded by a discrepancy in item counts between the exercise and the key, rendering the evaluation tool ineffective. While formatting and individual page structures are sound, the document requires immediate synchronization of content and keys to be fit for publication.\n"
          ]
        }
      ],
      "source": [
        "class EditorialDashboard(BaseModel):\n",
        "    manuscript_url: str\n",
        "    total_pages: int\n",
        "    grammar_issues: int\n",
        "    consistency_issues: int\n",
        "    formatting_issues: int\n",
        "    critical_pages: List[int] = Field(..., description=\"Pages with ‚â•3 high-sev issues\")\n",
        "    executive_summary: str\n",
        "\n",
        "dashboard, _ = chat_completion(\n",
        "    prompt=(\n",
        "        \"Create an editor‚Äôs dashboard summarizing the manuscript‚Äôs proofreading status. \"\n",
        "        \"Include total pages, issue counts by category, and list pages needing urgent attention. \"\n",
        "        \"Write a 3-sentence executive summary for the author.\"\n",
        "    ),\n",
        "    doc=BOOK_URL,\n",
        "    response_model=EditorialDashboard\n",
        ")\n",
        "\n",
        "print(\"üìã EDITORIAL DASHBOARD\")\n",
        "print(f\"Pages: {dashboard.total_pages}\")\n",
        "print(f\"Grammar: {dashboard.grammar_issues} | Consistency: {dashboard.consistency_issues} | Formatting: {dashboard.formatting_issues}\")\n",
        "print(f\"üö® Critical pages: {dashboard.critical_pages}\")\n",
        "print(f\"\\n{dashboard.executive_summary}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6fc61480",
      "metadata": {
        "id": "6fc61480"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "This cookbook shows how VLM Run Orion transforms raw PDF manuscripts into actionable editorial insights‚Äîno manual page-flipping required.\n",
        "\n",
        "\n",
        "### Key Takeaways\n",
        "\n",
        "1. Page-accurate feedback with contextual excerpts.\n",
        "\n",
        "2. Categorized issues (grammar, style, formatting, etc.).\n",
        "\n",
        "3. Chainable workflows run multiple specialized passes.\n",
        "\n",
        "4. Structured JSON output for integration into editing tools or CMS.\n",
        "\n",
        "5. Zero setup, no local OCR, NLP pipelines, or rule engines.\n",
        "\n",
        "\n",
        "### Use Cases\n",
        "\n",
        "- Self-publishing authors preparing for print\n",
        "- Publishing houses automating first-pass edits\n",
        "- Localization teams checking translated manuscripts\n",
        "- Accessibility auditors ensuring readable structure\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "- Explore the [VLM Run Documentation](https://docs.vlm.run) for more details\n",
        "- Join our [Discord community](https://discord.gg/AMApC2UzVY) for support\n",
        "- Check out more examples in the [VLM Run Cookbook](https://github.com/vlm-run/vlmrun-cookbook)\n",
        "- Review domain-specific redaction agents for financial, healthcare, legal, and other industries\n",
        "\n",
        "Happy building!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv (3.12.12)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
