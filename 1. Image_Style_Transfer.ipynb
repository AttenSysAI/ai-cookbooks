{"cells":[{"cell_type":"markdown","metadata":{"id":"JTXUTsrlRg2d"},"source":["<div align=\"center\">\n","<p align=\"center\" style=\"width: 100%;\">\n","    <img src=\"https://raw.githubusercontent.com/vlm-run/.github/refs/heads/main/profile/assets/vlm-black.svg\" alt=\"VLM Run Logo\" width=\"80\" style=\"margin-bottom: -5px; color: #2e3138; vertical-align: middle; padding-right: 5px;\"><br>\n","</p>\n","<p align=\"center\"><a href=\"https://docs.vlm.run\"><b>Website</b></a> | <a href=\"https://docs.vlm.run/\"><b>API Docs</b></a> | <a href=\"https://docs.vlm.run/blog\"><b>Blog</b></a> | <a href=\"https://discord.gg/AMApC2UzVY\"><b>Discord</b></a> | <a href=\"https://chat.vlm.run\"><b>Chat</b></a>\n","</p>\n","</div>\n","\n","# VLM Run Orion - Image-to-Image Style Transfer\n","\n","This comprehensive cookbook demonstrates [VLM Run Orion's](https://vlm.run/orion) image-to-image style transfer capabilities. For more details on the API, see the [Agent API docs](https://docs.vlm.run/agents/introduction).\n","\n","For this notebook, we'll cover how to use the **VLM Run Agent Chat Completions API** - an OpenAI-compatible interface for transferring artistic styles from one image to another with the same familiar chat-completions interface.\n","\n","We'll cover the following topics:\n"," 1. Basic Style Transfer (transfer style from one image to another)\n"," 2. Artistic Style Transfer (painting styles, artistic movements)\n"," 3. Photo-to-Painting Conversion\n"," 4. Style Transfer with Content Preservation\n"," 5. Multiple Style Variations\n"," 6. Style Intensity Control\n"," 7. Batch Style Transfer\n","\n","## Prerequisites\n","\n","- Python 3.10+\n","- VLM Run API key (get one at [app.vlm.run](https://app.vlm.run))\n","- VLM Run Python Client with OpenAI extra `vlmrun[openai]`\n"]},{"cell_type":"markdown","metadata":{"id":"_j9jBwU9Rg2i"},"source":["## Setup\n","\n","First, install the required packages and configure the environment.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IZgac0x8Rg2k","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1767461280211,"user_tz":-360,"elapsed":21071,"user":{"displayName":"Rezwan Islam Salvi","userId":"17143103905942797045"}},"outputId":"768a56df-7c29-48d1-f9b7-c4649c2b04d3"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m88.4/88.4 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.0/66.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m64.6/64.6 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m151.3/151.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m94.7/94.7 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m121.6/121.6 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m788.2/788.2 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["# Install required packages\n","%pip install vlmrun[openai] --upgrade --quiet\n","%pip install cachetools pillow requests numpy --quiet\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KB5wwJzWRg2m"},"outputs":[],"source":["import os\n","import getpass\n","\n","VLMRUN_API_KEY = os.getenv(\"VLMRUN_API_KEY\", None)\n","if VLMRUN_API_KEY is None:\n","    VLMRUN_API_KEY = getpass.getpass(\"Enter your VLM Run API key: \")\n"]},{"cell_type":"markdown","metadata":{"id":"4698NRBrRg2o"},"source":["## Initialize the VLM Run Client\n","\n","We use the OpenAI-compatible chat completions interface through the VLM Run SDK.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sADQUEd5Rg2q"},"outputs":[],"source":["from vlmrun.client import VLMRun\n","\n","BASE_URL = os.getenv(\"VLMRUN_BASE_URL\", \"https://agent.vlm.run/v1\")\n","client = VLMRun(api_key=VLMRUN_API_KEY, base_url=BASE_URL)\n","print(\"VLM Run client initialized successfully!\")\n","print(f\"Base URL: {BASE_URL}\")\n"]},{"cell_type":"markdown","metadata":{"id":"2SuUZCZBRg2s"},"source":["## Response Models (dtypes)\n","\n","We define Pydantic models for structured outputs. These models include **cached properties** that automatically download and convert images from URLs to PIL Images for easy manipulation.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Armx6cbORg2v"},"outputs":[],"source":["from typing import List\n","\n","from PIL import Image\n","from pydantic import BaseModel, Field\n","from vlmrun.common.utils import download_image\n","from vlmrun.types import ImageRef\n","\n","\n","class StyleTransferResponse(BaseModel):\n","    \"\"\"Response containing the style-transferred image.\"\"\"\n","    image: ImageRef = Field(..., description=\"The style-transferred image\")\n","\n","\n","class MultipleStyleTransferResponse(BaseModel):\n","    \"\"\"Response containing multiple style variations.\"\"\"\n","    images: List[ImageRef] = Field(..., description=\"List of style-transferred images with different variations\")\n","\n","print(\"Response models defined successfully!\")\n","print(\"Models include cached properties for automatic image downloading.\")\n"]},{"cell_type":"markdown","metadata":{"id":"HH5tNOUsRg2x"},"source":["## Helper Functions\n","\n","We create helper functions to simplify making chat completion requests with structured outputs.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yf5oSUT6Rg2z"},"outputs":[],"source":["import hashlib\n","import json\n","from typing import Any, Type, TypeVar\n","\n","import cachetools\n","from IPython.display import HTML\n","from vlmrun.common.image import encode_image\n","from pydantic import BaseModel\n","\n","\n","T = TypeVar('T', bound=BaseModel)\n","\n","\n","def display(images: Image.Image | list[Image.Image], texts: list[str] | None = None, width: int = 300):\n","    if isinstance(images, Image.Image):\n","        images = [images]\n","    if texts is None:\n","        texts = [None] * len(images)\n","    elif isinstance(texts, str):\n","        texts = [texts]\n","    elif len(texts) != len(images):\n","        raise ValueError(\"`texts` must be a list of the same length as `images`\")\n","\n","    imgs_html = \"\"\n","    for image, text in zip(images, texts):\n","        W, H = image.size\n","        if W > width:\n","            H = int(H * width / W)\n","            W = width\n","            image = image.resize((W, H))\n","        im_bytes = encode_image(image, format=\"JPEG\")\n","        imgs_html += f\"<div style='display:inline-block; margin:5px; text-align:center'>\"\n","        imgs_html += f\"<img src='{im_bytes}' style='width:{width}px; border-radius:6px'>\"\n","        if text:\n","            imgs_html += f\"<div style='font-size:12px; color:#666; margin-top:5px'>{text}</div>\"\n","        imgs_html += f\"</div>\"\n","    return HTML(f\"<div style='display:flex; flex-wrap:wrap'>{imgs_html}</div>\")\n","\n","\n","def custom_key(prompt: str, images: list[Image.Image] | list[str] | None = None, response_model: Type[T] | None = None, model: str = \"vlmrun-orion-1:auto\"):\n","    \"\"\"Custom key for caching chat_completion.\"\"\"\n","    image_keys = []\n","    for image in images:\n","        if isinstance(image, Image.Image):\n","            thumb = image.copy()\n","            thumb.thumbnail((128, 128))\n","            encoded = encode_image(thumb, format=\"JPEG\")\n","            image_keys.append(encoded)\n","        elif isinstance(image, str):\n","            image_keys.append(image)\n","\n","    response_key = hashlib.sha256(json.dumps(response_model.model_json_schema(), sort_keys=True).encode()).hexdigest() if response_model else \"\"\n","    return (prompt, tuple(image_keys), response_key, model)\n","\n","\n","@cachetools.cached(cache=cachetools.TTLCache(maxsize=1000, ttl=3600), key=custom_key)\n","def chat_completion(\n","    prompt: str,\n","    images: list[Image.Image] | list[str] | None = None,\n","    response_model: Type[T] | None = None,\n","    model: str = \"vlmrun-orion-1:fast\"\n",") -> tuple[str | BaseModel, str]:\n","    \"\"\"\n","    Make a chat completion request with optional images and structured output.\n","\n","    Args:\n","        prompt: The text prompt/instruction\n","        images: Optional list of images to process (either PIL Images or URLs)\n","        response_model: Optional Pydantic model for structured output\n","        model: Model to use (default: vlmrun-orion-1:fast)\n","\n","    Returns:\n","        Parsed response model if response_model provided, else raw response text\n","    \"\"\"\n","    content = []\n","    content.append({\"type\": \"text\", \"text\": prompt})\n","\n","    if images:\n","        for image in images:\n","            if isinstance(image, str):\n","                assert image.startswith(\"http\"), \"Image URLs must start with http or https\"\n","                content.append({\"type\": \"image_url\", \"image_url\": {\"url\": image, \"detail\": \"auto\"}})\n","            elif isinstance(image, Image.Image):\n","                content.append({\"type\": \"image_url\", \"image_url\": {\"url\": encode_image(image, format=\"JPEG\"), \"detail\": \"auto\"}})\n","            else:\n","                raise ValueError(\"Images must be either PIL Images or URLs\")\n","\n","    kwargs = {\n","        \"model\": model,\n","        \"messages\": [{\"role\": \"user\", \"content\": content}]\n","    }\n","\n","    if response_model:\n","        kwargs[\"response_format\"] = {\n","            \"type\": \"json_schema\",\n","            \"schema\": response_model.model_json_schema()\n","        }\n","\n","    response = client.agent.completions.create(**kwargs)\n","    response_text = response.choices[0].message.content\n","\n","    if response_model:\n","        return response_model.model_validate_json(response_text), response.session_id\n","\n","    return response_text, response.session_id\n","\n","print(\"Helper functions defined!\")\n"]},{"cell_type":"markdown","metadata":{"id":"_2tW0mKsRg23"},"source":["## Image-to-Image Style Transfer Capabilities\n","\n","VLM Run agents can transfer artistic styles from one image to another, creating stunning visual transformations while preserving the content structure of the original image.\n"]},{"cell_type":"markdown","metadata":{"id":"T9-ZlBucRg24"},"source":["### 1. Artistic Style Transfer\n","\n","Apply famous artistic styles (like Van Gogh, Monet, Picasso) to your images using style reference images.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xfHeqILkRg24"},"outputs":[],"source":["CONTENT_IMAGE_URL = \"https://storage.googleapis.com/vlm-data-public-prod/hub/examples/agent-media/white-sports-car-isolated-white-vector.avif\"\n","STYLE_IMAGE_URL = \"https://storage.googleapis.com/vlm-data-public-prod/hub/examples/agent-media/Vincent-van-Gogh-The-Starry-Night.webp\"\n","\n","content_img = download_image(CONTENT_IMAGE_URL)\n","style_img = download_image(STYLE_IMAGE_URL)\n","\n","print(\">> ORIGINAL IMAGES\")\n","display([content_img, style_img], texts=[\"Content Image\", \"Style Reference\"], width=400)\n"]},{"cell_type":"code","source":["result, session_id = chat_completion(\n","    prompt=\"Transfer the artistic style from the second image to the first image. Preserve the content and structure of the first image while applying the visual style, colors, and brushstrokes from the second image.\",\n","    images=[content_img, style_img],\n","    response_model=StyleTransferResponse,\n","    model=\"vlmrun-orion-1:auto\"\n",")\n","\n","print(\"\\n>> RESPONSE\")\n","print(result)\n","\n","# Get the style-transferred image\n","styled_img: Image.Image = client.artifacts.get(session_id=session_id, object_id=result.image.id)\n","print(\"\\n>> STYLE TRANSFERRED IMAGE\")\n","display(images=[styled_img], texts=[\"Style Transferred Result\"], width=600)"],"metadata":{"id":"Hy7TVtbjTyqC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KeUnGQy9Rg26"},"source":["### 2. Photo-to-Painting Conversion\n","\n","Convert photographs into paintings with various artistic styles.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2u2uHgXhRg26"},"outputs":[],"source":["PHOTO_URL = \"https://storage.googleapis.com/vlm-data-public-prod/hub/examples/image.agent/lunch-skyscraper.jpg\"\n","WATERCOLOR_STYLE_URL = \"https://storage.googleapis.com/vlm-data-public-prod/hub/examples/agent-media/background-art.jpg\"\n","\n","photo_img = download_image(PHOTO_URL)\n","watercolor_img = download_image(WATERCOLOR_STYLE_URL)\n","\n","print(\">> ORIGINAL IMAGES\")\n","display([photo_img, watercolor_img], texts=[\"Original Photo\", \"Watercolor Style\"], width=400)\n","\n"]},{"cell_type":"code","source":["result, session_id = chat_completion(\n","    prompt=\"Convert the first image (a photograph) into a watercolor painting using the style from the second image. Apply the characteristic watercolor effects: soft edges, translucent layers, and flowing colors while preserving the main subjects and composition.\",\n","    images=[PHOTO_URL, WATERCOLOR_STYLE_URL],\n","    response_model=StyleTransferResponse,\n","    model=\"vlmrun-orion-1:auto\"\n",")\n","\n","print(\"\\n>> RESPONSE\")\n","print(result)\n","\n","painted_img: Image.Image = client.artifacts.get(session_id=session_id, object_id=result.image.id)\n","print(\"\\n>> PAINTING RESULT\")\n","display(images=[painted_img], texts=[\"Watercolor Painting\"], width=600)"],"metadata":{"id":"i-9sTSsIUCFE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pR6yMfQRRg28"},"source":["### 3. Style Transfer with Content Preservation\n","\n","Transfer style while explicitly preserving important content elements like faces, objects, or specific details.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"65y6ISShRg29"},"outputs":[],"source":["# Example: Style transfer with face preservation\n","CONTENT_IMAGE_URL = \"https://storage.googleapis.com/vlm-data-public-prod/hub/examples/agent_use_cases/Headshot/headshot.jpg\"\n","ARTISTIC_STYLE_URL = \"https://storage.googleapis.com/vlm-data-public-prod/hub/examples/agent-media/background-art.jpg\"\n","\n","content_img = download_image(CONTENT_IMAGE_URL)\n","style_img = download_image(ARTISTIC_STYLE_URL)\n","\n","print(\">> ORIGINAL IMAGES\")\n","display([content_img, style_img], texts=[\"Content Image\", \"Artistic Style\"], width=400)\n"]},{"cell_type":"code","source":["result, session_id = chat_completion(\n","    prompt=\"Apply the artistic style from the second image to the first image, but preserve the faces and important details of the people. Keep the faces recognizable while applying the style to the background and other elements.\",\n","    images=[CONTENT_IMAGE_URL, ARTISTIC_STYLE_URL],\n","    response_model=StyleTransferResponse,\n","    model=\"vlmrun-orion-1:auto\"\n",")\n","\n","print(\"\\n>> RESPONSE\")\n","print(result)\n","\n","styled_img: Image.Image = client.artifacts.get(session_id=session_id, object_id=result.image.id)\n","print(\"\\n>> STYLE TRANSFERRED IMAGE\")\n","display(images=[styled_img], texts=[\"Style Transfer with Face Preservation\"], width=600)"],"metadata":{"id":"244VOGdMU-BT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jqGfCLuiRg2-"},"source":["### 4. Multiple Style Variations\n","\n","Generate multiple style transfer variations in a single request to explore different artistic interpretations.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2rKnnW0NRg2-"},"outputs":[],"source":["# Example: Generate multiple style variations\n","CONTENT_IMAGE_URL = \"https://storage.googleapis.com/vlm-data-public-prod/hub/examples/image.caption/car.jpg\"\n","STYLE_IMAGE_URL = \"https://storage.googleapis.com/vlm-data-public-prod/hub/examples/agent-media/background-art.jpg\"\n","\n","content_img = download_image(CONTENT_IMAGE_URL)\n","style_img = download_image(STYLE_IMAGE_URL)\n","\n","print(\">> ORIGINAL IMAGES\")\n","display([content_img, style_img], texts=[\"Content Image\", \"Style Reference\"], width=400)\n","\n"]},{"cell_type":"code","source":["result, session_id = chat_completion(\n","    prompt=\"Transfer the style from the second image to the first image. Generate 3 different variations with varying intensity levels: one subtle, one moderate, and one strong style application. Each should preserve the content structure but apply the style differently.\",\n","    images=[CONTENT_IMAGE_URL, STYLE_IMAGE_URL],\n","    response_model=MultipleStyleTransferResponse,\n","    model=\"vlmrun-orion-1:auto\"\n",")\n","\n","print(\"\\n>> RESPONSE\")\n","print(result)\n","\n","# Get all style variations\n","styled_images: List[Image.Image] = [\n","    client.artifacts.get(session_id=session_id, object_id=img.id)\n","    for img in result.images\n","]\n","\n","print(\"\\n>> STYLE VARIATIONS\")\n","display(\n","    styled_images,\n","    texts=[f\"Variation {i+1}\" for i in range(len(styled_images))],\n","    width=300\n",")"],"metadata":{"id":"BWJyQuU2VKRk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"X6lelKXQRg3A"},"source":["### 5. Batch Style Transfer\n","\n","Apply the same style to multiple content images efficiently.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8K6sa6nSRg3B"},"outputs":[],"source":["# Example: Apply same style to multiple images\n","STYLE_IMAGE_URL = \"https://storage.googleapis.com/vlm-data-public-prod/hub/examples/agent-media/background-art.jpg\"\n","CONTENT_IMAGES = [\n","    \"https://storage.googleapis.com/vlm-data-public-prod/hub/examples/image.caption/car.jpg\",\n","    \"https://storage.googleapis.com/vlm-data-public-prod/hub/examples/image.agent/lunch-skyscraper.jpg\"\n","]\n","\n","style_img = download_image(STYLE_IMAGE_URL)\n","content_imgs = [download_image(url) for url in CONTENT_IMAGES]\n","\n","print(\">> STYLE REFERENCE\")\n","display([style_img], texts=[\"Style Reference\"], width=400)\n","\n"]},{"cell_type":"code","source":["print(\"\\n>> ORIGINAL CONTENT IMAGES\")\n","display(content_imgs, texts=[f\"Content {i+1}\" for i in range(len(content_imgs))], width=300)"],"metadata":{"id":"LgFZdoMUVkPS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Apply style to each content image\n","styled_results = []\n","for i, content_url in enumerate(CONTENT_IMAGES):\n","    result, session_id = chat_completion(\n","        prompt=\"Transfer the artistic style from the second image to the first image. Preserve the content structure while applying the visual style.\",\n","        images=[content_url, STYLE_IMAGE_URL],\n","        response_model=StyleTransferResponse,\n","        model=\"vlmrun-orion-1:auto\"\n","    )\n","    styled_img = client.artifacts.get(session_id=session_id, object_id=result.image.id)\n","    styled_results.append(styled_img)\n","\n","print(\"\\n>> STYLE TRANSFERRED RESULTS\")\n","display(styled_results, texts=[f\"Styled {i+1}\" for i in range(len(styled_results))], width=300)"],"metadata":{"id":"isiS5xqOVgxi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fjM3e1EyRg3B"},"source":["### 6. Advanced: Combining Multiple Styles\n","\n","Combine elements from multiple style images to create unique artistic effects.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AG8roVjnRg3C"},"outputs":[],"source":["# Example: Combine multiple styles\n","CONTENT_IMAGE_URL = \"https://storage.googleapis.com/vlm-data-public-prod/hub/examples/image.caption/car.jpg\"\n","STYLE_1_URL = \"https://storage.googleapis.com/vlm-data-public-prod/hub/examples/agent-media/background-art.jpg\"\n","STYLE_2_URL = \"https://storage.googleapis.com/vlm-data-public-prod/hub/examples/agent-media/background_frame.jpg\"\n","\n","content_img = download_image(CONTENT_IMAGE_URL)\n","style1_img = download_image(STYLE_1_URL)\n","style2_img = download_image(STYLE_2_URL)\n","\n","print(\">> ORIGINAL IMAGES\")\n","display([content_img, style1_img, style2_img], texts=[\"Content\", \"Style 1\", \"Style 2\"], width=300)\n"]},{"cell_type":"code","source":["result, session_id = chat_completion(\n","    prompt=\"Transfer a combination of styles from the second and third images to the first image. Blend the color palette from the second image with the frame from the third image, creating a unique artistic fusion while preserving the content structure.\",\n","    images=[CONTENT_IMAGE_URL, STYLE_1_URL, STYLE_2_URL],\n","    response_model=StyleTransferResponse,\n","    model=\"vlmrun-orion-1:auto\"\n",")\n","\n","print(\"\\n>> RESPONSE\")\n","print(result)\n","\n","styled_img: Image.Image = client.artifacts.get(session_id=session_id, object_id=result.image.id)\n","print(\"\\n>> COMBINED STYLE RESULT\")\n","display(images=[styled_img], texts=[\"Combined Style Transfer\"], width=600)\n"],"metadata":{"id":"DtucYIFhV4QZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"znp1wZmFRg3D"},"source":["---\n","\n","## Conclusion\n","\n","This cookbook demonstrated the comprehensive style transfer capabilities of the **VLM Run Orion Image Agent API**.\n","\n","### Key Takeaways\n","\n","1. **OpenAI-Compatible Interface**: The API follows the OpenAI chat completions format, making it easy to integrate style transfer into existing workflows.\n","2. **Structured Outputs**: Use Pydantic models with `response_model` parameter to get type-safe, validated responses with automatic image retrieval.\n","3. **Flexible Prompting**: Natural language prompts allow you to control style intensity, preserve content, and combine multiple styles in a single request.\n","4. **Content Preservation**: You can explicitly instruct the model to preserve important elements like faces, objects, or specific details while applying style.\n","5. **Batch Processing**: Apply the same style to multiple images efficiently using loops and the caching mechanism.\n","6. **Multiple Variations**: Generate multiple style variations in a single request to explore different artistic interpretations.\n","\n","### Best Practices\n","\n","- **Style Intensity**: Use descriptive language (\"subtle\", \"moderate\", \"strong\") to control how much the style affects the content.\n","- **Content Preservation**: Be explicit about what elements to preserve (faces, objects, composition) when needed.\n","- **Model Selection**: Use `vlmrun-orion-1:auto` for complex style transfers and `vlmrun-orion-1:fast` for simpler tasks.\n","- **Caching**: The built-in caching mechanism helps reduce API calls when experimenting with the same images and prompts.\n","\n","### Next Steps\n","\n","- Explore the [VLM Run Documentation](https://docs.vlm.run) for more details\n","- Join our [Discord community](https://discord.gg/AMApC2UzVY) for support\n","- Check out more examples in the [VLM Run Cookbook](https://github.com/vlm-run/vlmrun-cookbook)\n","- Experiment with different style combinations and intensity levels\n","\n","Happy creating! ðŸŽ¨\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.13.9"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}