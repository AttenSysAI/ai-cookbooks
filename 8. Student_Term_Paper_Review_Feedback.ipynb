{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0b7f2dc7",
      "metadata": {
        "id": "0b7f2dc7"
      },
      "source": [
        "<div align=\"center\">\n",
        "<p align=\"center\" style=\"width: 100%;\">\n",
        "    <img src=\"https://raw.githubusercontent.com/vlm-run/.github/refs/heads/main/profile/assets/vlm-black.svg\" alt=\"VLM Run Logo\" width=\"80\" style=\"margin-bottom: -5px; color: #2e3138; vertical-align: middle; padding-right: 5px;\"><br>\n",
        "</p>\n",
        "<p align=\"center\">\n",
        "  <a href=\"https://docs.vlm.run\"><b>Website</b></a> | \n",
        "  <a href=\"https://docs.vlm.run/\"><b>API Docs</b></a> | \n",
        "  <a href=\"https://docs.vlm.run/blog\"><b>Blog</b></a> | \n",
        "  <a href=\"https://discord.gg/AMApC2UzVY\"><b>Discord</b></a> | \n",
        "  <a href=\"https://chat.vlm.run\"><b>Chat</b></a>\n",
        "</p>\n",
        "</div>\n",
        "\n",
        "# VLM Run Orion - Student Term Paper Review & Feedback\n",
        "\n",
        "\n",
        "This comprehensive cookbook demonstrates [VLM Run Orion's](https://vlm.run/orion) to automatically review student term papers (PDFs or images) and provide actionable, structured feedback. Whether you're an educator, TA, or student seeking self-review, Orion can evaluate clarity, argument strength, citation integrity, grammar, and formattingâ€”all with page-level precision.\n",
        "\n",
        "For this notebook, we'll cover how to use the **VLM Run Agent Chat Completions API**â€”an OpenAI-compatible interface that supports image and data inputs alongside textâ€”to generate plots directly from structured data.\n",
        "\n",
        "We'll cover the following topics:\n",
        "1. **Document Ingestion** â€“ Upload a student paper via URL\n",
        "\n",
        "2. **Academic Integrity Check** â€“ Detect missing citations, weak sources, or plagiarism signals\n",
        "\n",
        "3. **Writing Quality Assessment** â€“ Evaluate grammar, tone, structure, and coherence\n",
        "\n",
        "4. **Constructive Suggestions** â€“ Generate revision tips tailored to academic standards\n",
        "\n",
        "5. **Structured Output** â€“ Return machine-readable feedback for LMS integration\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "- Python 3.10+\n",
        "- VLM Run API key (get one at [app.vlm.run](https://app.vlm.run))\n",
        "- VLM Run Python Client with OpenAI extra: `pip install \"vlmrun[openai]\"`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43b58c5f",
      "metadata": {
        "id": "43b58c5f"
      },
      "source": [
        "## Setup\n",
        "\n",
        "First, install the required packages and configure the environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "53434b64",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53434b64",
        "outputId": "691e0956-41b4-4a5c-95fe-dc7b4ee00318"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.2 -> 25.3\n",
            "[notice] To update, run: C:\\Users\\User\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n",
            "\n",
            "[notice] A new release of pip is available: 25.2 -> 25.3\n",
            "[notice] To update, run: C:\\Users\\User\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install vlmrun[openai] --upgrade --quiet\n",
        "!pip install pillow requests numpy --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "fa9f8d78",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fa9f8d78",
        "outputId": "3b940c36-094d-4cbb-9a16-23f44049eadb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "import json\n",
        "from typing import List, Any\n",
        "from functools import cached_property\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "VLMRUN_API_KEY = os.getenv(\"VLMRUN_API_KEY\", None)\n",
        "if VLMRUN_API_KEY is None:\n",
        "    VLMRUN_API_KEY = getpass.getpass(\"Enter your VLM Run API key: \")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60b786ad",
      "metadata": {
        "id": "60b786ad"
      },
      "source": [
        "## Initialize the VLM Run Client\n",
        "\n",
        "We use the OpenAI-compatible chat completions interface through the VLM Run SDK."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "cf798bbb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf798bbb",
        "outputId": "1c7878de-e2fc-4832-eb62-c42b3e5ab524"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VLM Run client initialized successfully!\n",
            "Base URL: https://agent.vlm.run/v1\n",
            "Model: vlmrun-orion-1\n"
          ]
        }
      ],
      "source": [
        "from vlmrun.client import VLMRun\n",
        "\n",
        "client = VLMRun(\n",
        "    api_key=VLMRUN_API_KEY, base_url=\"https://agent.vlm.run/v1\", timeout=1000\n",
        ")\n",
        "print(\"VLM Run client initialized successfully!\")\n",
        "print(f\"Base URL: https://agent.vlm.run/v1\")\n",
        "print(f\"Model: vlmrun-orion-1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5df2b29e",
      "metadata": {
        "id": "5df2b29e"
      },
      "source": [
        "## Response Models (dtypes)\n",
        "\n",
        "We define structured Pydantic models to capture proofreading feedback with full traceability.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "010d3df2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "010d3df2",
        "outputId": "e9d166f7-370c-4cc0-cf6e-584481c93bf5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Proofreading response models defined!\n"
          ]
        }
      ],
      "source": [
        "class FeedbackItem(BaseModel):\n",
        "    category: str = Field(..., description=\"One of: 'grammar', 'clarity', 'argument', 'citation', 'formatting', 'originality'\")\n",
        "    page_number: int = Field(..., description=\"Page where issue occurs\")\n",
        "    excerpt: str = Field(..., description=\"Short quoted text\")\n",
        "    severity: str = Field(..., description=\"'low', 'medium', 'high'\")\n",
        "    suggestion: str = Field(..., description=\"Actionable revision advice\")\n",
        "    rationale: str = Field(..., description=\"Why this matters academically\")\n",
        "\n",
        "class TermPaperReview(BaseModel):\n",
        "    total_feedback_items: int\n",
        "    feedback_by_category: dict[str, int]\n",
        "    feedback: List[FeedbackItem]\n",
        "    overall_assessment: str = Field(..., description=\"Summary for instructor or student\")\n",
        "    grade_estimate: str = Field(..., description=\"e.g., 'A-', 'B+', 'Needs Major Revision'\")\n",
        "\n",
        "    def __repr__(self):\n",
        "        cats = ', '.join(f\"{k}={v}\" for k, v in self.feedback_by_category.items())\n",
        "        return f\"TermPaperReview(grade='{self.grade_estimate}', items={self.total_feedback_items}, categories=[{cats}])\"\n",
        "\n",
        "print(\"âœ… Proofreading response models defined!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b565e800",
      "metadata": {
        "id": "b565e800"
      },
      "source": [
        "## Helper Functions\n",
        "\n",
        "We create helper functions to simplify making chat completion requests with structured outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "f477c81b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f477c81b",
        "outputId": "5ec041bf-da87-4be4-fc0e-6e702f112a27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Helper functions defined!\n"
          ]
        }
      ],
      "source": [
        "import hashlib\n",
        "import cachetools\n",
        "from typing import Type, TypeVar\n",
        "from IPython.display import HTML\n",
        "from vlmrun.common.image import encode_image\n",
        "\n",
        "\n",
        "T = TypeVar('T', bound=BaseModel)\n",
        "\n",
        "\n",
        "def display(images: Image.Image | list[Image.Image], texts: list[str] | None = None, width: int = 300):\n",
        "    if isinstance(images, Image.Image):\n",
        "        images = [images]\n",
        "    if texts == None:\n",
        "        texts = [None] * len(images)\n",
        "    elif isinstance(texts, str):\n",
        "        texts = [texts]\n",
        "    elif len(texts) != len(images):\n",
        "        raise ValueError(\"`texts` must be a list of the same length as `images`\")\n",
        "\n",
        "    imgs_html = \"\"\n",
        "    for image, text in zip(images, texts):\n",
        "        W, H = image.size\n",
        "        if W > width:\n",
        "            H = int(H * width / W)\n",
        "            W = width\n",
        "            image = image.resize((W, H))\n",
        "        im_bytes = encode_image(image, format=\"JPEG\")\n",
        "        imgs_html += f\"<div style='display:inline-block; margin:5px; text-align:center'>\"\n",
        "        imgs_html += f\"<img src='{im_bytes}' style='width:{width}px; border-radius:6px'>\"\n",
        "        if text:\n",
        "            imgs_html += f\"<div style='font-size:12px; color:#666; margin-top:5px'>{text}</div>\"\n",
        "        imgs_html += f\"</div>\"\n",
        "    return HTML(f\"<div style='display:flex; flex-wrap:wrap'>{imgs_html}</div>\")\n",
        "\n",
        "\n",
        "def custom_key(prompt: str, images: list[Image.Image] | list[str] | None = None, doc: list[str] | None = None, response_model: Type[T] | None = None, model: str = \"vlmrun-orion-1:auto\"):\n",
        "    \"\"\"Custom key for caching chat_completion.\"\"\"\n",
        "    image_keys = []\n",
        "    if images:\n",
        "        for image in images:\n",
        "            if isinstance(image, Image.Image):\n",
        "                thumb = image.copy()\n",
        "                thumb.thumbnail((128, 128))\n",
        "                encoded = encode_image(thumb, format=\"JPEG\")\n",
        "                image_keys.append(encoded)\n",
        "            elif isinstance(image, str):\n",
        "                image_keys.append(image)\n",
        "\n",
        "    doc_keys = []\n",
        "    if doc:\n",
        "        if isinstance(doc, str):\n",
        "            doc_keys.append(doc)\n",
        "        elif isinstance(doc, list):\n",
        "            for d_url in doc:\n",
        "                doc_keys.append(d_url)\n",
        "\n",
        "    response_key = hashlib.sha256(json.dumps(response_model.model_json_schema(), sort_keys=True).encode()).hexdigest() if response_model else \"\"\n",
        "    return (prompt, tuple(image_keys), tuple(doc_keys), response_key, model)\n",
        "\n",
        "\n",
        "@cachetools.cached(cache=cachetools.TTLCache(maxsize=1000, ttl=3600), key=custom_key)\n",
        "def chat_completion(\n",
        "    prompt: str,\n",
        "    images: list[Image.Image] | list[str] | None = None,\n",
        "    doc: list[str] | None = None,\n",
        "    response_model: Type[T] | None = None,\n",
        "    model: str = \"vlmrun-orion-1:auto\"\n",
        ") -> Any:\n",
        "    \"\"\"\n",
        "    Make a chat completion request with optional images and structured output.\n",
        "\n",
        "    Args:\n",
        "        prompt: The text prompt/instruction\n",
        "        images: Optional list of images to process (either PIL Images or URLs)\n",
        "        response_model: Optional Pydantic model for structured output\n",
        "        model: Model to use (default: vlmrun-orion-1:auto)\n",
        "\n",
        "    Returns:\n",
        "        Parsed response model if response_model provided, else raw response text\n",
        "    \"\"\"\n",
        "    content = []\n",
        "    content.append({\"type\": \"text\", \"text\": prompt})\n",
        "    if doc:\n",
        "        if isinstance(doc, str):\n",
        "            content.append({\n",
        "                    \"type\": \"file_url\",\n",
        "                    \"file_url\": {\"url\": doc, \"detail\": \"auto\"}\n",
        "                })\n",
        "        elif isinstance(doc, list):\n",
        "            for d_url in doc:\n",
        "                assert isinstance(d_url, str) and d_url.startswith(\"http\"), \"Document URLs must be strings starting with http or https\"\n",
        "                content.append({\n",
        "                    \"type\": \"file_url\",\n",
        "                    \"file_url\": {\"url\": d_url, \"detail\": \"auto\"}\n",
        "                })\n",
        "\n",
        "\n",
        "    if images:\n",
        "        for image in images:\n",
        "            if isinstance(image, str):\n",
        "                assert image.startswith(\"http\"), \"Image URLs must start with http or https\"\n",
        "                content.append({\n",
        "                    \"type\": \"image_url\",\n",
        "                    \"image_url\": {\"url\": image, \"detail\": \"auto\"}\n",
        "                })\n",
        "            elif isinstance(image, Image.Image):\n",
        "                content.append({\n",
        "                    \"type\": \"image_url\",\n",
        "                    \"image_url\": {\"url\": encode_image(image, format=\"JPEG\"), \"detail\": \"auto\"}\n",
        "                })\n",
        "            else:\n",
        "                raise ValueError(\"Images must be either PIL Images or URLs\")\n",
        "\n",
        "    kwargs = {\n",
        "        \"model\": model,\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": content}]\n",
        "    }\n",
        "\n",
        "    if response_model:\n",
        "        kwargs[\"response_format\"] = {\n",
        "            \"type\": \"json_schema\",\n",
        "            \"schema\": response_model.model_json_schema()\n",
        "        }\n",
        "\n",
        "    response = client.agent.completions.create(**kwargs)\n",
        "    response_text = response.choices[0].message.content\n",
        "\n",
        "    if response_model:\n",
        "        return response_model.model_validate_json(response_text), response.session_id\n",
        "\n",
        "    return response_text, response.session_id\n",
        "\n",
        "print(\"Helper functions defined!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd5579ed",
      "metadata": {
        "id": "cd5579ed"
      },
      "source": [
        "### 1. Full Academic Review Pass\n",
        "\n",
        "\n",
        "Upload a student paper and request comprehensive feedback."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "435a8e69",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 644
        },
        "id": "435a8e69",
        "outputId": "4dede5ef-b628-463d-a04c-1d09550a351d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“„ Paper reviewed across 8 pages\n",
            "ğŸ“Š Grade estimate: F\n",
            "â— Total feedback items: 8\n",
            "ğŸ“‚ By category: {}\n",
            "\n",
            "ğŸ“ Overall Assessment:\n",
            "This document fails to meet the basic standards of an academic term paper. It is a 'Frankenstein' document composed of disparate, uncredited sources, including customer complaints and technical engineering papers. The presence of watermarks from 'free paper' websites and browser screenshots indicates a total lack of original work and severe plagiarism. Formatting is unprofessional, and the grammar is severely compromised by the incorrect use of Title Case.\n"
          ]
        }
      ],
      "source": [
        "PAPER_URL = \"https://isagraf.ru/images/industry_avt/soft/isagraf/Bata%20Shoe%20Organization-Term-Paper.pdf\" \n",
        "\n",
        "review, session_id = chat_completion(\n",
        "    prompt=(\n",
        "        \"You are a university teaching assistant reviewing a student's term paper. \"\n",
        "        \"Evaluate the paper for: \"\n",
        "        \"- Clarity and academic tone \"\n",
        "        \"- Logical flow and argument strength \"\n",
        "        \"- Proper citation (APA/MLA-style assumed) \"\n",
        "        \"- Grammar, punctuation, and sentence structure \"\n",
        "        \"- Formatting consistency (headings, margins, etc.) \"\n",
        "        \"Return only high- and medium-severity issues with page numbers, excerpts, and specific suggestions. \"\n",
        "        \"Conclude with an overall assessment and estimated letter grade.\"\n",
        "    ),\n",
        "    doc=PAPER_URL,\n",
        "    response_model=TermPaperReview\n",
        ")\n",
        "\n",
        "print(f\"ğŸ“„ Paper reviewed across {len(set(f.page_number for f in review.feedback))} pages\")\n",
        "print(f\"ğŸ“Š Grade estimate: {review.grade_estimate}\")\n",
        "print(f\"â— Total feedback items: {review.total_feedback_items}\")\n",
        "print(f\"ğŸ“‚ By category: {review.feedback_by_category}\\n\")\n",
        "print(\"ğŸ“ Overall Assessment:\")\n",
        "print(review.overall_assessment)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "acf8dbd8",
      "metadata": {
        "id": "acf8dbd8"
      },
      "source": [
        "### 2. Citation & Plagiarism Signal Check\n",
        "\n",
        "Focus specifically on source integrity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "0c6cdaad",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        },
        "id": "0c6cdaad",
        "outputId": "0e603700-dcf8-4c48-c0ab-ee0166f92109"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ” Citation-related flags: 3\n",
            "\n",
            "Page 4 | Formatting (medium)\n",
            "Excerpt: â€œï³ï¥ï¬ï¬ï³ï€ ïï¶ï¥ï²ï€ ï€´ï€µï€ ïï©ï¬ï¬ï©ï¯ï®... ïƒï¯ï®ï´ï²ï©ï¢ïµï´ï¥ï³ï€ ï´ï¯ï€ ï´ï¨ï¥ï€ ï³ïµï³ï´ï¡ï©ï®ï¡ï¢ï¬ï¥ï€ ï¤ï¥ï¶ï¥ï¬ï¯ï°ï­ï¥ï®ï´â€\n",
            "Suggestion: Verify the original source of this text and ensure proper paraphrasing and attribution.\n",
            "\n",
            "Page 8 | Citation (high)\n",
            "Excerpt: â€œWe Are Currently Investigating The Use Of Mobile Platforms... For Automatic Assembly Tasks.â€\n",
            "Suggestion: Attribute this technical description to the original research team or paper.\n",
            "\n",
            "Page 9 | Formatting (high)\n",
            "Excerpt: â€œ(Russian text block follows English description of shoe components)â€\n",
            "Suggestion: Remove redundant foreign language text and cite the source of the technical information.\n"
          ]
        }
      ],
      "source": [
        "citation_check, _ = chat_completion(\n",
        "    prompt=(\n",
        "        \"Scan the paper for potential academic integrity issues: \"\n",
        "        \"- Missing in-text citations for claims or data \"\n",
        "        \"- Over-reliance on single sources \"\n",
        "        \"- Suspicious phrasing that may indicate uncited paraphrasing \"\n",
        "        \"- Mismatched reference list entries \"\n",
        "        \"Do not accuseâ€”flag only *potential* concerns needing human review.\"\n",
        "    ),\n",
        "    doc=PAPER_URL,\n",
        "    response_model=TermPaperReview\n",
        ")\n",
        "\n",
        "print(f\"ğŸ” Citation-related flags: {len([f for f in citation_check.feedback if f.category == 'citation'])}\")\n",
        "for item in citation_check.feedback[:3]:\n",
        "    print(f\"\\nPage {item.page_number} | {item.category.title()} ({item.severity})\")\n",
        "    print(f\"Excerpt: â€œ{item.excerpt}â€\")\n",
        "    print(f\"Suggestion: {item.suggestion}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd2f704c",
      "metadata": {
        "id": "fd2f704c"
      },
      "source": [
        "### 3. Writing Style & Tone Refinement\n",
        "\n",
        "Help students sound more scholarly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "25a98b2a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "25a98b2a",
        "outputId": "f577fb84-2d25-4d56-f2b8-c255990a7e30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ–‹ï¸ Style suggestions: 5\n"
          ]
        }
      ],
      "source": [
        "style_pass, _ = chat_completion(\n",
        "    prompt=(\n",
        "        \"Identify informal language, vague claims, passive overuse, or weak transitions. \"\n",
        "        \"Suggest improvements that elevate academic tone without changing meaning. \"\n",
        "        \"Focus on undergrad-level expectations.\"\n",
        "    ),\n",
        "    doc=PAPER_URL,\n",
        "    response_model=TermPaperReview\n",
        ")\n",
        "\n",
        "print(f\"ğŸ–‹ï¸ Style suggestions: {len(style_pass.feedback)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "baa3fdbe",
      "metadata": {},
      "source": [
        "### 4. Generate Instructor Summary\n",
        "\n",
        "Condense feedback into a grading memo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "6e90b185",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“¬ INSTRUCTOR MEMO\n",
            "Title: Operations Management Analysis: Bata Shoe Organization and Bata India\n",
            "Recommended Grade: B+\n",
            "\n",
            "âœ… Strengths:\n",
            "  â€¢ In-depth technical analysis of manufacturing processes, including the ellipsoidal conveyor system.\n",
            "  â€¢ Strong contextualization of the \"Bata System\" and its impact on internal cost accounting.\n",
            "  â€¢ Comprehensive overview of facility planning and global supply chain logistics.\n",
            "\n",
            "ğŸ”§ Areas for Improvement:\n",
            "  â€¢ Integrate critical analysis for the raw consumer complaints to bridge data with operational solutions.\n",
            "  â€¢ Increase the use of peer-reviewed scholarly sources beyond company-specific documentation.\n",
            "  â€¢ Refine transitions between the technical manufacturing simulations and the broader business strategy sections.\n",
            "\n",
            "â¡ï¸ Next Steps: Analyze consumer feedback to identify operational fixes, add 3-4 scholarly sources on management theory, and smooth the structural flow between sections.\n"
          ]
        }
      ],
      "source": [
        "class InstructorMemo(BaseModel):\n",
        "    student_name: str = Field(default=\"Anonymous\")\n",
        "    paper_title: str\n",
        "    strengths: List[str]\n",
        "    areas_for_improvement: List[str]\n",
        "    recommended_grade: str\n",
        "    next_steps: str\n",
        "\n",
        "memo, _ = chat_completion(\n",
        "    prompt=(\n",
        "        \"Write a 5-sentence instructor memo summarizing this student paper. \"\n",
        "        \"Highlight 2-3 strengths, 2-3 improvement areas, suggest a grade, \"\n",
        "        \"and recommend next steps (e.g., 'revise intro', 'add 2 scholarly sources').\"\n",
        "    ),\n",
        "    doc=PAPER_URL,\n",
        "    response_model=InstructorMemo\n",
        ")\n",
        "\n",
        "print(\"ğŸ“¬ INSTRUCTOR MEMO\")\n",
        "print(f\"Title: {memo.paper_title}\")\n",
        "print(f\"Recommended Grade: {memo.recommended_grade}\\n\")\n",
        "print(\"âœ… Strengths:\")\n",
        "for s in memo.strengths:\n",
        "    print(f\"  â€¢ {s}\")\n",
        "print(\"\\nğŸ”§ Areas for Improvement:\")\n",
        "for a in memo.areas_for_improvement:\n",
        "    print(f\"  â€¢ {a}\")\n",
        "print(f\"\\nâ¡ï¸ Next Steps: {memo.next_steps}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6fc61480",
      "metadata": {
        "id": "6fc61480"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "VLM Run Orion turns subjective grading into structured, scalable, and supportive feedbackâ€”ideal for:\n",
        "\n",
        "- Teachers managing large cohorts\n",
        "\n",
        "- Students seeking pre-submission self-review\n",
        "\n",
        "- Writing centers offering automated first-pass analysis\n",
        "\n",
        "\n",
        "\n",
        "### Key Takeaways\n",
        "\n",
        "- ğŸ“‘ Page-accurate feedback with direct quotes\n",
        "\n",
        "- ğŸ¯ Rubric-aligned categories (argument, citation, clarity, etc.)\n",
        "\n",
        "- ğŸ’¬ Constructiveâ€”not punitiveâ€”suggestions\n",
        "\n",
        "- âš™ï¸ OpenAI-compatible API for easy automation\n",
        "\n",
        "\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "- Explore the [VLM Run Documentation](https://docs.vlm.run) for more details\n",
        "- Join our [Discord community](https://discord.gg/AMApC2UzVY) for support\n",
        "- Check out more examples in the [VLM Run Cookbook](https://github.com/vlm-run/vlmrun-cookbook)\n",
        "- Review domain-specific redaction agents for financial, healthcare, legal, and other industries\n",
        "\n",
        "Happy building!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
